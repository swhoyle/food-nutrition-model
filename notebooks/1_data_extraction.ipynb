{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696ee7aa",
   "metadata": {},
   "source": [
    "# Step 1: Data Extraction\n",
    "\n",
    "## Purpose\n",
    "The purpose of this notebook is to download the Open Food Facts dataset ([food.parquet on Hugging Face](https://huggingface.co/datasets/openfoodfacts/product-database/blob/main/food.parquet)), perform an initial data inspection, and extract a relevant subset tailored for this project.\n",
    "\n",
    "The raw dataset contains nearly 4 million rows and 110 columns, including several semi-structured JSON fields that require parsing and transformation. We need understanding the structure, cleaning, and selecting the essential features needed for subsequent EDA and preprocessing steps.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Tasks\n",
    "- Connect to Hugging Face and download the raw dataset.\n",
    "- Inspect dataset structure: review number of rows, columns, datatypes, and memory usage.\n",
    "- Filter and clean the dataset:\n",
    "    - Filter rows based on project-specific conditions.\n",
    "    - Select relevant columns required for analysis.\n",
    "    - Parse JSON fields and flatten nested structures.\n",
    "    - Format and rename columns for clarity and consistency.\n",
    "- Save the extracted dataset\n",
    "\n",
    "---\n",
    "\n",
    "## Output\n",
    "- `food.csv` — a filtered and structured dataset ready for preprocessing and EDA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d77a88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e8eb23",
   "metadata": {},
   "source": [
    "#### 1. Download the dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c6f859a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset '../data/food.parquet' already exists locally. Skipping download.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://huggingface.co/datasets/openfoodfacts/product-database/resolve/main/food.parquet\"\n",
    "dataset_path = \"../data/food.parquet\"\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"Dataset '{dataset_path}' already exists locally. Skipping download.\\n\")\n",
    "\n",
    "else:\n",
    "    print(f\"Downloading '{dataset_path}' from Hugging Face...\")\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(dataset_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "    print(f\"Dataset successfully downloaded and saved to '{dataset_path}'.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce2317",
   "metadata": {},
   "source": [
    "#### 2. Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fab851e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 110)\n",
      "additives_n                      float64\n",
      "additives_tags                    object\n",
      "allergens_tags                    object\n",
      "brands_tags                       object\n",
      "brands                            object\n",
      "                                  ...   \n",
      "unknown_ingredients_n            float64\n",
      "unknown_nutrients_tags            object\n",
      "vitamins_tags                     object\n",
      "with_non_nutritive_sweeteners    float64\n",
      "with_sweeteners                  float64\n",
      "Length: 110, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additives_n</th>\n",
       "      <th>additives_tags</th>\n",
       "      <th>allergens_tags</th>\n",
       "      <th>brands_tags</th>\n",
       "      <th>brands</th>\n",
       "      <th>categories</th>\n",
       "      <th>categories_tags</th>\n",
       "      <th>categories_properties</th>\n",
       "      <th>checkers_tags</th>\n",
       "      <th>ciqual_food_name_tags</th>\n",
       "      <th>...</th>\n",
       "      <th>states_tags</th>\n",
       "      <th>stores_tags</th>\n",
       "      <th>stores</th>\n",
       "      <th>traces_tags</th>\n",
       "      <th>unique_scans_n</th>\n",
       "      <th>unknown_ingredients_n</th>\n",
       "      <th>unknown_nutrients_tags</th>\n",
       "      <th>vitamins_tags</th>\n",
       "      <th>with_non_nutritive_sweeteners</th>\n",
       "      <th>with_sweeteners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[en:nuts]</td>\n",
       "      <td>[xx:bovetti]</td>\n",
       "      <td>Bovetti</td>\n",
       "      <td>Petit-déjeuners,Produits à tartiner,Produits à...</td>\n",
       "      <td>[en:breakfasts, en:spreads, en:sweet-spreads, ...</td>\n",
       "      <td>{'ciqual_food_code': 31032.0, 'agribalyse_food...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[chocolate-spread-with-hazelnuts]</td>\n",
       "      <td>...</td>\n",
       "      <td>[en:to-be-completed, en:nutrition-facts-comple...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[lagg-s]</td>\n",
       "      <td>Lagg's</td>\n",
       "      <td>null</td>\n",
       "      <td>[en:null]</td>\n",
       "      <td>{'ciqual_food_code': None, 'agribalyse_food_co...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[unknown]</td>\n",
       "      <td>...</td>\n",
       "      <td>[en:to-be-completed, en:nutrition-facts-comple...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[lagg-s]</td>\n",
       "      <td>Lagg's</td>\n",
       "      <td>Plant-based foods and beverages, Beverages, Ho...</td>\n",
       "      <td>[en:plant-based-foods-and-beverages, en:bevera...</td>\n",
       "      <td>{'ciqual_food_code': 18020.0, 'agribalyse_food...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[unknown]</td>\n",
       "      <td>...</td>\n",
       "      <td>[en:to-be-completed, en:nutrition-facts-comple...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[xx:lagg-s]</td>\n",
       "      <td>Lagg's</td>\n",
       "      <td>Beverages and beverages preparations, Plant-ba...</td>\n",
       "      <td>[en:beverages-and-beverages-preparations, en:p...</td>\n",
       "      <td>{'ciqual_food_code': 18020.0, 'agribalyse_food...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[unknown]</td>\n",
       "      <td>...</td>\n",
       "      <td>[en:to-be-completed, en:nutrition-facts-comple...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[lagg-s]</td>\n",
       "      <td>Lagg's</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ciqual_food_code': None, 'agribalyse_food_co...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[unknown]</td>\n",
       "      <td>...</td>\n",
       "      <td>[en:to-be-completed, en:nutrition-facts-comple...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   additives_n additives_tags allergens_tags   brands_tags   brands  \\\n",
       "0          NaN           None      [en:nuts]  [xx:bovetti]  Bovetti   \n",
       "1          0.0             []             []      [lagg-s]   Lagg's   \n",
       "2          0.0             []             []      [lagg-s]   Lagg's   \n",
       "3          0.0             []             []   [xx:lagg-s]   Lagg's   \n",
       "4          0.0             []             []      [lagg-s]   Lagg's   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Petit-déjeuners,Produits à tartiner,Produits à...   \n",
       "1                                               null   \n",
       "2  Plant-based foods and beverages, Beverages, Ho...   \n",
       "3  Beverages and beverages preparations, Plant-ba...   \n",
       "4                                               None   \n",
       "\n",
       "                                     categories_tags  \\\n",
       "0  [en:breakfasts, en:spreads, en:sweet-spreads, ...   \n",
       "1                                          [en:null]   \n",
       "2  [en:plant-based-foods-and-beverages, en:bevera...   \n",
       "3  [en:beverages-and-beverages-preparations, en:p...   \n",
       "4                                               None   \n",
       "\n",
       "                               categories_properties checkers_tags  \\\n",
       "0  {'ciqual_food_code': 31032.0, 'agribalyse_food...            []   \n",
       "1  {'ciqual_food_code': None, 'agribalyse_food_co...            []   \n",
       "2  {'ciqual_food_code': 18020.0, 'agribalyse_food...            []   \n",
       "3  {'ciqual_food_code': 18020.0, 'agribalyse_food...            []   \n",
       "4  {'ciqual_food_code': None, 'agribalyse_food_co...            []   \n",
       "\n",
       "               ciqual_food_name_tags  ...  \\\n",
       "0  [chocolate-spread-with-hazelnuts]  ...   \n",
       "1                          [unknown]  ...   \n",
       "2                          [unknown]  ...   \n",
       "3                          [unknown]  ...   \n",
       "4                          [unknown]  ...   \n",
       "\n",
       "                                         states_tags stores_tags stores  \\\n",
       "0  [en:to-be-completed, en:nutrition-facts-comple...          []          \n",
       "1  [en:to-be-completed, en:nutrition-facts-comple...        None   None   \n",
       "2  [en:to-be-completed, en:nutrition-facts-comple...        None   None   \n",
       "3  [en:to-be-completed, en:nutrition-facts-comple...        None   None   \n",
       "4  [en:to-be-completed, en:nutrition-facts-comple...        None   None   \n",
       "\n",
       "   traces_tags  unique_scans_n unknown_ingredients_n unknown_nutrients_tags  \\\n",
       "0           []             1.0                   NaN                     []   \n",
       "1           []             1.0                   0.0                     []   \n",
       "2           []             NaN                   0.0                     []   \n",
       "3           []             NaN                   1.0                     []   \n",
       "4           []             NaN                   0.0                     []   \n",
       "\n",
       "   vitamins_tags with_non_nutritive_sweeteners with_sweeteners  \n",
       "0             []                           NaN             NaN  \n",
       "1             []                           NaN             NaN  \n",
       "2             []                           NaN             NaN  \n",
       "3             []                           NaN             NaN  \n",
       "4             []                           NaN             NaN  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first 100 rows\n",
    "parquet_file = pq.ParquetFile(dataset_path)\n",
    "batch = next(parquet_file.iter_batches(batch_size=100, columns=None))\n",
    "df_first_100 = batch.to_pandas()\n",
    "print(df_first_100.shape)\n",
    "print(df_first_100.dtypes)\n",
    "df_first_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6795f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the first 100 rows to a JSON file\n",
    "df_first_100.to_json(\"../data/raw_dataset_subset.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832137c8",
   "metadata": {},
   "source": [
    "#### 3. Filter and clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3c96257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to parse / clean specific columns\n",
    "\n",
    "def parse_tags(tags):\n",
    "  if isinstance(tags, (np.ndarray, list, tuple, pd.Series)):\n",
    "      if len(tags) == 0:\n",
    "          return []\n",
    "      tags = [str(tag) for tag in tags if tag is not None]\n",
    "  else:\n",
    "      return []\n",
    "  return [tag.split(\":\")[-1] for tag in tags if tag.startswith(\"en:\") and tag.split(\":\")[-1] != 'null']\n",
    "\n",
    "\n",
    "def parse_ingredients(ing_str):\n",
    "  try:\n",
    "      ings = json.loads(ing_str) if isinstance(ing_str, str) else ing_str\n",
    "      return [item.get(\"text\").lower() for item in ings] if isinstance(ings, list) else []\n",
    "  except:\n",
    "      return []\n",
    "  \n",
    "\n",
    "def extract_nutriments(nutriments_list):\n",
    "  if not isinstance(nutriments_list, (np.ndarray, list, tuple, pd.Series)):\n",
    "      return pd.Series()\n",
    "\n",
    "  nutri_dict = {item['name'].replace('-', '_'): item.get('100g') or item.get('value') for item in nutriments_list\n",
    "                if item['name'] in [\"energy\", \"sugars\", \"added-sugars\", \"carbohydrates\", \"salt\", \"fat\", \"trans-fat\", \"proteins\"]}\n",
    "  return pd.Series(nutri_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0afb827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataset in batches (size = 10000)...\n",
      "Processing batch 1 (rows 1-10000)...\n",
      "Processing batch 2 (rows 10001-20000)...\n",
      "Processing batch 3 (rows 20001-30000)...\n",
      "Processing batch 4 (rows 30001-40000)...\n",
      "Processing batch 5 (rows 40001-50000)...\n",
      "Processing batch 6 (rows 50001-60000)...\n",
      "Processing batch 7 (rows 60001-70000)...\n",
      "Processing batch 8 (rows 70001-80000)...\n",
      "Processing batch 9 (rows 80001-90000)...\n",
      "Processing batch 10 (rows 90001-100000)...\n",
      "Processing batch 11 (rows 100001-110000)...\n",
      "Processing batch 12 (rows 110001-120000)...\n",
      "Processing batch 13 (rows 120001-130000)...\n",
      "Processing batch 14 (rows 130001-140000)...\n",
      "Processing batch 15 (rows 140001-150000)...\n",
      "Processing batch 16 (rows 150001-160000)...\n",
      "Processing batch 17 (rows 160001-170000)...\n",
      "Processing batch 18 (rows 170001-180000)...\n",
      "Processing batch 19 (rows 180001-190000)...\n",
      "Processing batch 20 (rows 190001-200000)...\n",
      "Processing batch 21 (rows 200001-210000)...\n",
      "Processing batch 22 (rows 210001-220000)...\n",
      "Processing batch 23 (rows 220001-230000)...\n",
      "Processing batch 24 (rows 230001-240000)...\n",
      "Processing batch 25 (rows 240001-250000)...\n",
      "Processing batch 26 (rows 250001-260000)...\n",
      "Processing batch 27 (rows 260001-270000)...\n",
      "Processing batch 28 (rows 270001-280000)...\n",
      "Processing batch 29 (rows 280001-290000)...\n",
      "Processing batch 30 (rows 290001-300000)...\n",
      "Processing batch 31 (rows 300001-310000)...\n",
      "Processing batch 32 (rows 310001-320000)...\n",
      "Processing batch 33 (rows 320001-330000)...\n",
      "Processing batch 34 (rows 330001-340000)...\n",
      "Processing batch 35 (rows 340001-350000)...\n",
      "Processing batch 36 (rows 350001-360000)...\n",
      "Processing batch 37 (rows 360001-370000)...\n",
      "Processing batch 38 (rows 370001-380000)...\n",
      "Processing batch 39 (rows 380001-390000)...\n",
      "Processing batch 40 (rows 390001-400000)...\n",
      "Processing batch 41 (rows 400001-410000)...\n",
      "Processing batch 42 (rows 410001-420000)...\n",
      "Processing batch 43 (rows 420001-430000)...\n",
      "Processing batch 44 (rows 430001-440000)...\n",
      "Processing batch 45 (rows 440001-450000)...\n",
      "Processing batch 46 (rows 450001-460000)...\n",
      "Processing batch 47 (rows 460001-470000)...\n",
      "Processing batch 48 (rows 470001-480000)...\n",
      "Processing batch 49 (rows 480001-490000)...\n",
      "Processing batch 50 (rows 490001-500000)...\n",
      "Processing batch 51 (rows 500001-510000)...\n",
      "Processing batch 52 (rows 510001-520000)...\n",
      "Processing batch 53 (rows 520001-530000)...\n",
      "Processing batch 54 (rows 530001-540000)...\n",
      "Processing batch 55 (rows 540001-550000)...\n",
      "Processing batch 56 (rows 550001-560000)...\n",
      "Processing batch 57 (rows 560001-570000)...\n",
      "Processing batch 58 (rows 570001-580000)...\n",
      "Processing batch 59 (rows 580001-590000)...\n",
      "Processing batch 60 (rows 590001-600000)...\n",
      "Processing batch 61 (rows 600001-610000)...\n",
      "Processing batch 62 (rows 610001-620000)...\n",
      "Processing batch 63 (rows 620001-630000)...\n",
      "Processing batch 64 (rows 630001-640000)...\n",
      "Processing batch 65 (rows 640001-650000)...\n",
      "Processing batch 66 (rows 650001-660000)...\n",
      "Processing batch 67 (rows 660001-670000)...\n",
      "Processing batch 68 (rows 670001-680000)...\n",
      "Processing batch 69 (rows 680001-690000)...\n",
      "Processing batch 70 (rows 690001-700000)...\n",
      "Processing batch 71 (rows 700001-710000)...\n",
      "Processing batch 72 (rows 710001-720000)...\n",
      "Processing batch 73 (rows 720001-730000)...\n",
      "Processing batch 74 (rows 730001-740000)...\n",
      "Processing batch 75 (rows 740001-750000)...\n",
      "Processing batch 76 (rows 750001-760000)...\n",
      "Processing batch 77 (rows 760001-770000)...\n",
      "Processing batch 78 (rows 770001-780000)...\n",
      "Processing batch 79 (rows 780001-790000)...\n",
      "Processing batch 80 (rows 790001-800000)...\n",
      "Processing batch 81 (rows 800001-810000)...\n",
      "Processing batch 82 (rows 810001-820000)...\n",
      "Processing batch 83 (rows 820001-830000)...\n",
      "Processing batch 84 (rows 830001-840000)...\n",
      "Processing batch 85 (rows 840001-850000)...\n",
      "Processing batch 86 (rows 850001-860000)...\n",
      "Processing batch 87 (rows 860001-870000)...\n",
      "Processing batch 88 (rows 870001-880000)...\n",
      "Processing batch 89 (rows 880001-890000)...\n",
      "Processing batch 90 (rows 890001-900000)...\n",
      "Processing batch 91 (rows 900001-910000)...\n",
      "Processing batch 92 (rows 910001-920000)...\n",
      "Processing batch 93 (rows 920001-930000)...\n",
      "Processing batch 94 (rows 930001-940000)...\n",
      "Processing batch 95 (rows 940001-950000)...\n",
      "Processing batch 96 (rows 950001-960000)...\n",
      "Processing batch 97 (rows 960001-970000)...\n",
      "Processing batch 98 (rows 970001-980000)...\n",
      "Processing batch 99 (rows 980001-990000)...\n",
      "Processing batch 100 (rows 990001-1000000)...\n",
      "Processing batch 101 (rows 1000001-1010000)...\n",
      "Processing batch 102 (rows 1010001-1020000)...\n",
      "Processing batch 103 (rows 1020001-1030000)...\n",
      "Processing batch 104 (rows 1030001-1040000)...\n",
      "Processing batch 105 (rows 1040001-1050000)...\n",
      "Processing batch 106 (rows 1050001-1060000)...\n",
      "Processing batch 107 (rows 1060001-1070000)...\n",
      "Processing batch 108 (rows 1070001-1080000)...\n",
      "Processing batch 109 (rows 1080001-1090000)...\n",
      "Processing batch 110 (rows 1090001-1100000)...\n",
      "Processing batch 111 (rows 1100001-1110000)...\n",
      "Processing batch 112 (rows 1110001-1120000)...\n",
      "Processing batch 113 (rows 1120001-1130000)...\n",
      "Processing batch 114 (rows 1130001-1140000)...\n",
      "Processing batch 115 (rows 1140001-1150000)...\n",
      "Processing batch 116 (rows 1150001-1160000)...\n",
      "Processing batch 117 (rows 1160001-1170000)...\n",
      "Processing batch 118 (rows 1170001-1180000)...\n",
      "Processing batch 119 (rows 1180001-1190000)...\n",
      "Processing batch 120 (rows 1190001-1200000)...\n",
      "Processing batch 121 (rows 1200001-1210000)...\n",
      "Processing batch 122 (rows 1210001-1220000)...\n",
      "Processing batch 123 (rows 1220001-1230000)...\n",
      "Processing batch 124 (rows 1230001-1240000)...\n",
      "Processing batch 125 (rows 1240001-1250000)...\n",
      "Processing batch 126 (rows 1250001-1260000)...\n",
      "Processing batch 127 (rows 1260001-1270000)...\n",
      "Processing batch 128 (rows 1270001-1280000)...\n",
      "Processing batch 129 (rows 1280001-1290000)...\n",
      "Processing batch 130 (rows 1290001-1300000)...\n",
      "Processing batch 131 (rows 1300001-1310000)...\n",
      "Processing batch 132 (rows 1310001-1320000)...\n",
      "Processing batch 133 (rows 1320001-1330000)...\n",
      "Processing batch 134 (rows 1330001-1340000)...\n",
      "Processing batch 135 (rows 1340001-1350000)...\n",
      "Processing batch 136 (rows 1350001-1360000)...\n",
      "Processing batch 137 (rows 1360001-1370000)...\n",
      "Processing batch 138 (rows 1370001-1380000)...\n",
      "Processing batch 139 (rows 1380001-1390000)...\n",
      "Processing batch 140 (rows 1390001-1400000)...\n",
      "Processing batch 141 (rows 1400001-1410000)...\n",
      "Processing batch 142 (rows 1410001-1420000)...\n",
      "Processing batch 143 (rows 1420001-1430000)...\n",
      "Processing batch 144 (rows 1430001-1440000)...\n",
      "Processing batch 145 (rows 1440001-1450000)...\n",
      "Processing batch 146 (rows 1450001-1460000)...\n",
      "Processing batch 147 (rows 1460001-1470000)...\n",
      "Processing batch 148 (rows 1470001-1480000)...\n",
      "Processing batch 149 (rows 1480001-1490000)...\n",
      "Processing batch 150 (rows 1490001-1500000)...\n",
      "Processing batch 151 (rows 1500001-1510000)...\n",
      "Processing batch 152 (rows 1510001-1520000)...\n",
      "Processing batch 153 (rows 1520001-1530000)...\n",
      "Processing batch 154 (rows 1530001-1540000)...\n",
      "Processing batch 155 (rows 1540001-1550000)...\n",
      "Processing batch 156 (rows 1550001-1560000)...\n",
      "Processing batch 157 (rows 1560001-1570000)...\n",
      "Processing batch 158 (rows 1570001-1580000)...\n",
      "Processing batch 159 (rows 1580001-1590000)...\n",
      "Processing batch 160 (rows 1590001-1600000)...\n",
      "Processing batch 161 (rows 1600001-1610000)...\n",
      "Processing batch 162 (rows 1610001-1620000)...\n",
      "Processing batch 163 (rows 1620001-1630000)...\n",
      "Processing batch 164 (rows 1630001-1640000)...\n",
      "Processing batch 165 (rows 1640001-1650000)...\n",
      "Processing batch 166 (rows 1650001-1660000)...\n",
      "Processing batch 167 (rows 1660001-1670000)...\n",
      "Processing batch 168 (rows 1670001-1680000)...\n",
      "Processing batch 169 (rows 1680001-1690000)...\n",
      "Processing batch 170 (rows 1690001-1700000)...\n",
      "Processing batch 171 (rows 1700001-1710000)...\n",
      "Processing batch 172 (rows 1710001-1720000)...\n",
      "Processing batch 173 (rows 1720001-1730000)...\n",
      "Processing batch 174 (rows 1730001-1740000)...\n",
      "Processing batch 175 (rows 1740001-1750000)...\n",
      "Processing batch 176 (rows 1750001-1760000)...\n",
      "Processing batch 177 (rows 1760001-1770000)...\n",
      "Processing batch 178 (rows 1770001-1780000)...\n",
      "Processing batch 179 (rows 1780001-1790000)...\n",
      "Processing batch 180 (rows 1790001-1800000)...\n",
      "Processing batch 181 (rows 1800001-1810000)...\n",
      "Processing batch 182 (rows 1810001-1820000)...\n",
      "Processing batch 183 (rows 1820001-1830000)...\n",
      "Processing batch 184 (rows 1830001-1840000)...\n",
      "Processing batch 185 (rows 1840001-1850000)...\n",
      "Processing batch 186 (rows 1850001-1860000)...\n",
      "Processing batch 187 (rows 1860001-1870000)...\n",
      "Processing batch 188 (rows 1870001-1880000)...\n",
      "Processing batch 189 (rows 1880001-1890000)...\n",
      "Processing batch 190 (rows 1890001-1900000)...\n",
      "Processing batch 191 (rows 1900001-1910000)...\n",
      "Processing batch 192 (rows 1910001-1920000)...\n",
      "Processing batch 193 (rows 1920001-1930000)...\n",
      "Processing batch 194 (rows 1930001-1940000)...\n",
      "Processing batch 195 (rows 1940001-1950000)...\n",
      "Processing batch 196 (rows 1950001-1960000)...\n",
      "Processing batch 197 (rows 1960001-1970000)...\n",
      "Processing batch 198 (rows 1970001-1980000)...\n",
      "Processing batch 199 (rows 1980001-1990000)...\n",
      "Processing batch 200 (rows 1990001-2000000)...\n",
      "Processing batch 201 (rows 2000001-2010000)...\n",
      "Processing batch 202 (rows 2010001-2020000)...\n",
      "Processing batch 203 (rows 2020001-2030000)...\n",
      "Processing batch 204 (rows 2030001-2040000)...\n",
      "Processing batch 205 (rows 2040001-2050000)...\n",
      "Processing batch 206 (rows 2050001-2060000)...\n",
      "Processing batch 207 (rows 2060001-2070000)...\n",
      "Processing batch 208 (rows 2070001-2080000)...\n",
      "Processing batch 209 (rows 2080001-2090000)...\n",
      "Processing batch 210 (rows 2090001-2100000)...\n",
      "Processing batch 211 (rows 2100001-2110000)...\n",
      "Processing batch 212 (rows 2110001-2120000)...\n",
      "Processing batch 213 (rows 2120001-2130000)...\n",
      "Processing batch 214 (rows 2130001-2140000)...\n",
      "Processing batch 215 (rows 2140001-2150000)...\n",
      "Processing batch 216 (rows 2150001-2160000)...\n",
      "Processing batch 217 (rows 2160001-2170000)...\n",
      "Processing batch 218 (rows 2170001-2180000)...\n",
      "Processing batch 219 (rows 2180001-2190000)...\n",
      "Processing batch 220 (rows 2190001-2200000)...\n",
      "Processing batch 221 (rows 2200001-2210000)...\n",
      "Processing batch 222 (rows 2210001-2220000)...\n",
      "Processing batch 223 (rows 2220001-2230000)...\n",
      "Processing batch 224 (rows 2230001-2240000)...\n",
      "Processing batch 225 (rows 2240001-2250000)...\n",
      "Processing batch 226 (rows 2250001-2260000)...\n",
      "Processing batch 227 (rows 2260001-2270000)...\n",
      "Processing batch 228 (rows 2270001-2280000)...\n",
      "Processing batch 229 (rows 2280001-2290000)...\n",
      "Processing batch 230 (rows 2290001-2300000)...\n",
      "Processing batch 231 (rows 2300001-2310000)...\n",
      "Processing batch 232 (rows 2310001-2320000)...\n",
      "Processing batch 233 (rows 2320001-2330000)...\n",
      "Processing batch 234 (rows 2330001-2340000)...\n",
      "Processing batch 235 (rows 2340001-2350000)...\n",
      "Processing batch 236 (rows 2350001-2360000)...\n",
      "Processing batch 237 (rows 2360001-2370000)...\n",
      "Processing batch 238 (rows 2370001-2380000)...\n",
      "Processing batch 239 (rows 2380001-2390000)...\n",
      "Processing batch 240 (rows 2390001-2400000)...\n",
      "Processing batch 241 (rows 2400001-2410000)...\n",
      "Processing batch 242 (rows 2410001-2420000)...\n",
      "Processing batch 243 (rows 2420001-2430000)...\n",
      "Processing batch 244 (rows 2430001-2440000)...\n",
      "Processing batch 245 (rows 2440001-2450000)...\n",
      "Processing batch 246 (rows 2450001-2460000)...\n",
      "Processing batch 247 (rows 2460001-2470000)...\n",
      "Processing batch 248 (rows 2470001-2480000)...\n",
      "Processing batch 249 (rows 2480001-2490000)...\n",
      "Processing batch 250 (rows 2490001-2500000)...\n",
      "Processing batch 251 (rows 2500001-2510000)...\n",
      "Processing batch 252 (rows 2510001-2520000)...\n",
      "Processing batch 253 (rows 2520001-2530000)...\n",
      "Processing batch 254 (rows 2530001-2540000)...\n",
      "Processing batch 255 (rows 2540001-2550000)...\n",
      "Processing batch 256 (rows 2550001-2560000)...\n",
      "Processing batch 257 (rows 2560001-2570000)...\n",
      "Processing batch 258 (rows 2570001-2580000)...\n",
      "Processing batch 259 (rows 2580001-2590000)...\n",
      "Processing batch 260 (rows 2590001-2600000)...\n",
      "Processing batch 261 (rows 2600001-2610000)...\n",
      "Processing batch 262 (rows 2610001-2620000)...\n",
      "Processing batch 263 (rows 2620001-2630000)...\n",
      "Processing batch 264 (rows 2630001-2640000)...\n",
      "Processing batch 265 (rows 2640001-2650000)...\n",
      "Processing batch 266 (rows 2650001-2660000)...\n",
      "Processing batch 267 (rows 2660001-2670000)...\n",
      "Processing batch 268 (rows 2670001-2680000)...\n",
      "Processing batch 269 (rows 2680001-2690000)...\n",
      "Processing batch 270 (rows 2690001-2700000)...\n",
      "Processing batch 271 (rows 2700001-2710000)...\n",
      "Processing batch 272 (rows 2710001-2720000)...\n",
      "Processing batch 273 (rows 2720001-2730000)...\n",
      "Processing batch 274 (rows 2730001-2740000)...\n",
      "Processing batch 275 (rows 2740001-2750000)...\n",
      "Processing batch 276 (rows 2750001-2760000)...\n",
      "Processing batch 277 (rows 2760001-2770000)...\n",
      "Processing batch 278 (rows 2770001-2780000)...\n",
      "Processing batch 279 (rows 2780001-2790000)...\n",
      "Processing batch 280 (rows 2790001-2800000)...\n",
      "Processing batch 281 (rows 2800001-2810000)...\n",
      "Processing batch 282 (rows 2810001-2820000)...\n",
      "Processing batch 283 (rows 2820001-2830000)...\n",
      "Processing batch 284 (rows 2830001-2840000)...\n",
      "Processing batch 285 (rows 2840001-2850000)...\n",
      "Processing batch 286 (rows 2850001-2860000)...\n",
      "Processing batch 287 (rows 2860001-2870000)...\n",
      "Processing batch 288 (rows 2870001-2880000)...\n",
      "Processing batch 289 (rows 2880001-2890000)...\n",
      "Processing batch 290 (rows 2890001-2900000)...\n",
      "Processing batch 291 (rows 2900001-2910000)...\n",
      "Processing batch 292 (rows 2910001-2920000)...\n",
      "Processing batch 293 (rows 2920001-2930000)...\n",
      "Processing batch 294 (rows 2930001-2940000)...\n",
      "Processing batch 295 (rows 2940001-2950000)...\n",
      "Processing batch 296 (rows 2950001-2960000)...\n",
      "Processing batch 297 (rows 2960001-2970000)...\n",
      "Processing batch 298 (rows 2970001-2980000)...\n",
      "Processing batch 299 (rows 2980001-2990000)...\n",
      "Processing batch 300 (rows 2990001-3000000)...\n",
      "Processing batch 301 (rows 3000001-3010000)...\n",
      "Processing batch 302 (rows 3010001-3020000)...\n",
      "Processing batch 303 (rows 3020001-3030000)...\n",
      "Processing batch 304 (rows 3030001-3040000)...\n",
      "Processing batch 305 (rows 3040001-3050000)...\n",
      "Processing batch 306 (rows 3050001-3060000)...\n",
      "Processing batch 307 (rows 3060001-3070000)...\n",
      "Processing batch 308 (rows 3070001-3080000)...\n",
      "Processing batch 309 (rows 3080001-3090000)...\n",
      "Processing batch 310 (rows 3090001-3100000)...\n",
      "Processing batch 311 (rows 3100001-3110000)...\n",
      "Processing batch 312 (rows 3110001-3120000)...\n",
      "Processing batch 313 (rows 3120001-3130000)...\n",
      "Processing batch 314 (rows 3130001-3140000)...\n",
      "Processing batch 315 (rows 3140001-3150000)...\n",
      "Processing batch 316 (rows 3150001-3160000)...\n",
      "Processing batch 317 (rows 3160001-3170000)...\n",
      "Processing batch 318 (rows 3170001-3180000)...\n",
      "Processing batch 319 (rows 3180001-3190000)...\n",
      "Processing batch 320 (rows 3190001-3200000)...\n",
      "Processing batch 321 (rows 3200001-3210000)...\n",
      "Processing batch 322 (rows 3210001-3220000)...\n",
      "Processing batch 323 (rows 3220001-3230000)...\n",
      "Processing batch 324 (rows 3230001-3240000)...\n",
      "Processing batch 325 (rows 3240001-3250000)...\n",
      "Processing batch 326 (rows 3250001-3260000)...\n",
      "Processing batch 327 (rows 3260001-3270000)...\n",
      "Processing batch 328 (rows 3270001-3280000)...\n",
      "Processing batch 329 (rows 3280001-3290000)...\n",
      "Processing batch 330 (rows 3290001-3300000)...\n",
      "Processing batch 331 (rows 3300001-3310000)...\n",
      "Processing batch 332 (rows 3310001-3320000)...\n",
      "Processing batch 333 (rows 3320001-3330000)...\n",
      "Processing batch 334 (rows 3330001-3340000)...\n",
      "Processing batch 335 (rows 3340001-3350000)...\n",
      "Processing batch 336 (rows 3350001-3360000)...\n",
      "Processing batch 337 (rows 3360001-3370000)...\n",
      "Processing batch 338 (rows 3370001-3380000)...\n",
      "Processing batch 339 (rows 3380001-3390000)...\n",
      "Processing batch 340 (rows 3390001-3400000)...\n",
      "Processing batch 341 (rows 3400001-3410000)...\n",
      "Processing batch 342 (rows 3410001-3420000)...\n",
      "Processing batch 343 (rows 3420001-3430000)...\n",
      "Processing batch 344 (rows 3430001-3440000)...\n",
      "Processing batch 345 (rows 3440001-3450000)...\n",
      "Processing batch 346 (rows 3450001-3460000)...\n",
      "Processing batch 347 (rows 3460001-3470000)...\n",
      "Processing batch 348 (rows 3470001-3480000)...\n",
      "Processing batch 349 (rows 3480001-3490000)...\n",
      "Processing batch 350 (rows 3490001-3500000)...\n",
      "Processing batch 351 (rows 3500001-3510000)...\n",
      "Processing batch 352 (rows 3510001-3520000)...\n",
      "Processing batch 353 (rows 3520001-3530000)...\n",
      "Processing batch 354 (rows 3530001-3540000)...\n",
      "Processing batch 355 (rows 3540001-3550000)...\n",
      "Processing batch 356 (rows 3550001-3560000)...\n",
      "Processing batch 357 (rows 3560001-3570000)...\n",
      "Processing batch 358 (rows 3570001-3580000)...\n",
      "Processing batch 359 (rows 3580001-3590000)...\n",
      "Processing batch 360 (rows 3590001-3600000)...\n",
      "Processing batch 361 (rows 3600001-3610000)...\n",
      "Processing batch 362 (rows 3610001-3620000)...\n",
      "Processing batch 363 (rows 3620001-3630000)...\n",
      "Processing batch 364 (rows 3630001-3640000)...\n",
      "Processing batch 365 (rows 3640001-3650000)...\n",
      "Processing batch 366 (rows 3650001-3660000)...\n",
      "Processing batch 367 (rows 3660001-3670000)...\n",
      "Processing batch 368 (rows 3670001-3680000)...\n",
      "Processing batch 369 (rows 3680001-3690000)...\n",
      "Processing batch 370 (rows 3690001-3700000)...\n",
      "Processing batch 371 (rows 3700001-3710000)...\n",
      "Processing batch 372 (rows 3710001-3720000)...\n",
      "Processing batch 373 (rows 3720001-3730000)...\n",
      "Processing batch 374 (rows 3730001-3740000)...\n",
      "Processing batch 375 (rows 3740001-3750000)...\n",
      "Processing batch 376 (rows 3750001-3760000)...\n",
      "Processing batch 377 (rows 3760001-3770000)...\n",
      "Processing batch 378 (rows 3770001-3780000)...\n",
      "Processing batch 379 (rows 3780001-3790000)...\n",
      "Processing batch 380 (rows 3790001-3800000)...\n",
      "Processing batch 381 (rows 3800001-3810000)...\n",
      "Processing batch 382 (rows 3810001-3820000)...\n",
      "Processing batch 383 (rows 3820001-3830000)...\n",
      "Processing batch 384 (rows 3830001-3840000)...\n",
      "Processing batch 385 (rows 3840001-3850000)...\n",
      "Processing batch 386 (rows 3850001-3860000)...\n",
      "Processing batch 387 (rows 3860001-3870000)...\n",
      "Processing batch 388 (rows 3870001-3880000)...\n",
      "Processing batch 389 (rows 3880001-3890000)...\n",
      "Processing batch 390 (rows 3890001-3900000)...\n",
      "Processing batch 391 (rows 3900001-3910000)...\n",
      "Processing batch 392 (rows 3910001-3920000)...\n",
      "Processing batch 393 (rows 3920001-3930000)...\n",
      "Processing batch 394 (rows 3930001-3940000)...\n",
      "Processing batch 395 (rows 3940001-3950000)...\n",
      "Processing batch 396 (rows 3950001-3960000)...\n",
      "Processing batch 397 (rows 3960001-3970000)...\n",
      "Processing batch 398 (rows 3970001-3980000)...\n",
      "Processing batch 399 (rows 3980001-3990000)...\n",
      "Processing batch 400 (rows 3990001-4000000)...\n",
      "Processing batch 401 (rows 4000001-4010000)...\n",
      "Processing batch 402 (rows 4010001-4020000)...\n",
      "Processing batch 403 (rows 4020001-4030000)...\n",
      "Processing batch 404 (rows 4030001-4040000)...\n",
      "Processing batch 405 (rows 4040001-4050000)...\n",
      "Processing batch 406 (rows 4050001-4060000)...\n",
      "Processing batch 407 (rows 4060001-4070000)...\n",
      "Processing batch 408 (rows 4070001-4080000)...\n",
      "Processing batch 409 (rows 4080001-4090000)...\n",
      "\n",
      "Processing complete. Output saved to ../data/food.csv.\n"
     ]
    }
   ],
   "source": [
    "output_dataset = \"../data/food.csv\"\n",
    "\n",
    "# Remove output file if it exists\n",
    "if os.path.exists(output_dataset):\n",
    "    os.remove(output_dataset)\n",
    "\n",
    "required_columns = [\n",
    "    \"code\", \"brands\", \"product_name\", \"categories_tags\", \"food_groups_tags\", \"labels_tags\",\n",
    "    \"ingredients_n\", \"ingredients_from_palm_oil_n\", \"ingredients\", \"nutriments\",\n",
    "    \"nutriscore_grade\", \"lang\", \"additives_n\", \"additives_tags\", \"allergens_tags\",\n",
    "    \"ingredients_analysis_tags\", \"completeness\"\n",
    "]\n",
    "\n",
    "parquet_file = pq.ParquetFile(dataset_path)\n",
    "batch_size = 10000\n",
    "i = 0\n",
    "\n",
    "print(f\"Cleaning dataset in batches (size = {batch_size})...\")\n",
    "\n",
    "for batch in parquet_file.iter_batches(batch_size=batch_size, columns=required_columns):\n",
    "    print(f\"Processing batch {i+1} (rows {batch_size*i + 1}-{batch_size*(i+1)})...\")\n",
    "\n",
    "    df = batch.to_pandas()\n",
    "\n",
    "    # Filter out invalid or blank nutriscore grade\n",
    "    df = df[df[\"nutriscore_grade\"].isin([\"a\", \"b\", \"c\", \"d\", \"e\"])]\n",
    "\n",
    "    # Filter out products with no ingredients\n",
    "    df = df[~df[\"ingredients\"].isna()]\n",
    "\n",
    "    # Filter for English language products\n",
    "    df = df[df[\"lang\"] == \"en\"]\n",
    "\n",
    "    # Skip empty batches\n",
    "    if df.empty:\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # Get product name\n",
    "    df[\"product\"] = df[\"product_name\"].apply(lambda x: x[0][\"text\"] if isinstance(x, np.ndarray) and len(x) > 0 and \"text\" in x[0] else x)\n",
    "    \n",
    "    # Parse ingredients\n",
    "    df[\"ingredients\"] = df[\"ingredients\"].apply(parse_ingredients)\n",
    "\n",
    "    # Parse nutriments\n",
    "    nutri_extracted = df[\"nutriments\"].apply(extract_nutriments)\n",
    "    for col in nutri_extracted.columns:\n",
    "        df[col] = nutri_extracted[col]\n",
    "    df.drop(columns=[\"nutriments\"], inplace=True)\n",
    "\n",
    "    # Clean tags\n",
    "    for c in df.columns:\n",
    "        if c.endswith(\"_tags\"):\n",
    "            df[c] = df[c].apply(lambda x: [item.replace(\"en:\", \"\") for item in x] if isinstance(x, np.ndarray) else str(x))\n",
    "\n",
    "    # Reorder and ensure all final columns exist\n",
    "    final_cols = [\n",
    "        \"code\", \"brands\", \"product\", \"lang\", \"categories_tags\", \"food_groups_tags\", \"labels_tags\",\n",
    "        \"additives_n\", \"additives_tags\", \"allergens_tags\",\n",
    "        \"ingredients_analysis_tags\", \"ingredients_n\", \"ingredients_from_palm_oil_n\", \"ingredients\",\n",
    "        \"completeness\", \"energy\", \"sugars\", \"added_sugars\", \"carbohydrates\", \"salt\", \"fat\",\n",
    "        \"trans_fat\", \"proteins\", \"nutriscore_grade\"\n",
    "    ]\n",
    "    for col in final_cols:\n",
    "        if col not in df:\n",
    "            df[col] = None\n",
    "    df = df[final_cols]\n",
    "\n",
    "    # Write batch to CSV incrementally\n",
    "    if i == 0:\n",
    "        header_written = False\n",
    "    else:\n",
    "        header_written = True\n",
    "\n",
    "    df.to_csv(output_dataset, mode='a', header=not header_written, index=False)\n",
    "\n",
    "    # Free memory\n",
    "    del df, nutri_extracted, batch\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(f\"\\nProcessing complete. Output saved to {output_dataset}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3585c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424297, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/dqqbfzkd0ln207r8z90_jbnc0000gp/T/ipykernel_57773/1698039606.py:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(output_dataset)\n"
     ]
    }
   ],
   "source": [
    "# Read and display the cleaned dataset\n",
    "df = pd.read_csv(output_dataset)\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "# Save the first 100 rows of the cleaned dataset to a JSON file\n",
    "df.head(100).to_json(\"../data/cleaned_dataset_subset.json\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
